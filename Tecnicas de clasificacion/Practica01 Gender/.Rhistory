# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
# Establezco la semilla aleatoria
set.seed(247)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.06382979 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(247)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.06382979 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
# predicción con la muestra de validacion
arbol.pred <- predict(arbol.podado, df.validate, type="class")
arbol.perf <- table(df.validate$Gender, arbol.pred,
dnn=c("Actual", "Predicted"))
arbol.perf
#vamos a comparar que hubiera pasasdo si no lo hubiéramos podado:
arbol.pred1 <- predict(arbol, df.validate, type="class")
arbol.perf1 <- table(df.validate$Gender, arbol.pred1,
dnn=c("Actual", "Predicted"))
arbol.perf1
# En conclusion vemos que nuestro arbol podado sale igual que si no lo podamos, es decir, hemos ahorrado en complejidad
#lo representamos en un grafico diferente.
library(partykit)
plot(as.party(arbol.podado))
# Establezco la semilla aleatoria
set.seed(347)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(347)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.03260870 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
# Establezco la semilla aleatoria
set.seed(1047)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(107)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(107)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.01000000 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(107)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.01000000 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
# predicción con la muestra de validacion
arbol.pred <- predict(arbol.podado, df.validate, type="class")
arbol.perf <- table(df.validate$Gender, arbol.pred,
dnn=c("Actual", "Predicted"))
arbol.perf
#vamos a comparar que hubiera pasasdo si no lo hubiéramos podado:
arbol.pred1 <- predict(arbol, df.validate, type="class")
arbol.perf1 <- table(df.validate$Gender, arbol.pred1,
dnn=c("Actual", "Predicted"))
arbol.perf1
# En conclusion vemos que nuestro arbol podado sale igual que si no lo podamos, es decir, hemos ahorrado en complejidad
#lo representamos en un grafico diferente.
library(partykit)
plot(as.party(arbol.podado))
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(101)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.04081633 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(101)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.04081633 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
# predicción con la muestra de validacion
arbol.pred <- predict(arbol.podado, df.validate, type="class")
arbol.perf <- table(df.validate$Gender, arbol.pred,
dnn=c("Actual", "Predicted"))
arbol.perf
#vamos a comparar que hubiera pasasdo si no lo hubiéramos podado:
arbol.pred1 <- predict(arbol, df.validate, type="class")
arbol.perf1 <- table(df.validate$Gender, arbol.pred1,
dnn=c("Actual", "Predicted"))
arbol.perf1
# En conclusion vemos que nuestro arbol podado sale igual que si no lo podamos, es decir, hemos ahorrado en complejidad
#lo representamos en un grafico diferente.
library(partykit)
plot(as.party(arbol.podado))
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(111)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(246)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
#Al tratarse de un proyecto nuevo, tenemos establecida como carpeta ruta la carpeta en la que está el proyecto, en donde hemos guardado los demas archivos, por lo que no hace falta volver a definir la ruta
getwd()
gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv")
head(gender, 6) # Comprobamos el encabezado de gender
plot(gender$Gender)
table(gender$Gender)
length(gender$Gender[gender$Gender=="Female"])
# Hay 140 female y 68 male, por lo que el 67.3% de la muestra es female
# Establezco la semilla aleatoria
set.seed(246)
train <- sample(nrow(gender), 0.7*nrow(gender))
# Creo los data frames para la muestra de entrenamiento y validación
df.train <- gender[train,]
df.validate <- gender[-train,]
# Volvemos a hacer la gráfica para comprobar si mantiene la proporción
par(mfrow=c(1,2))    #esta línea realiza ambos graficos juntos, lo que nos facilita la comparación visual.
plot(df.train$Gender)
table(df.train$Gender)
# comprobamos que en la muestra hay 96 female y 49 male.
plot(df.validate$Gender)
table(df.validate$Gender)
# tenemos un total de 44 female y 19 male.
# Los resultados tanto de la muestra de entrenamiento como de la muestra de validación parecen estar bien distribuidos, por lo que trabajaremos con ellas.
library(rpart)
# Estimamos el arbol
arbol <- rpart(Gender ~ ., data=df.train, method="class",
parms=list(split="information"))
print(arbol)
summary(arbol)
#dibujamos el arbol sin podar
library(rpart.plot)
prp(arbol, type=2, extra=104, fallen.leaves= TRUE, main="arbol general")
#miramos el cp y escogemos el punto de corte donde tenga el menor error que en este caso es el cuarto o el quinto. Podamos e cuarto.
arbol$cptable
# Representamos gráficamente la curva cp
plotcp(arbol)
arbol.podado <- prune(arbol, cp= 0.02127660 )
print(arbol.podado)
# y volvemos a pintar el arbol una vez podado
prp(arbol.podado, type = 2, extra = 104,
fallen.leaves = TRUE, main="Arbol final")
# predicción con la muestra de validacion
arbol.pred <- predict(arbol.podado, df.validate, type="class")
arbol.perf <- table(df.validate$Gender, arbol.pred,
dnn=c("Actual", "Predicted"))
arbol.perf
#vamos a comparar que hubiera pasasdo si no lo hubiéramos podado:
arbol.pred1 <- predict(arbol, df.validate, type="class")
arbol.perf1 <- table(df.validate$Gender, arbol.pred1,
dnn=c("Actual", "Predicted"))
arbol.perf1
# En conclusion vemos que nuestro arbol podado sale igual que si no lo podamos, es decir, hemos ahorrado en complejidad
#lo representamos en un grafico diferente.
library(partykit)
plot(as.party(arbol.podado))
knit_with_parameters('~/Documents/CUNEF/Tecnicas de clasificación/Practicas a entregar/Practica01 Gender/practica01.Rmd')
